# CH-10 — Assessment & Outcomes
**Status:** Draft (v0.1)  
**Purpose:** Define how outcomes are measured, reported, and improved—without gaming metrics or hiding gaps.

---

## 1) Purpose
Assessment exists to:
- verify learning (mastery)
- guide support (intervention)
- prove integrity (receipts)
- improve the system (continuous improvement)

## 2) Scope
Applies to:
- formative + summative assessment
- portfolios and proof-of-learning artifacts
- reporting cadence (monthly/quarterly/annual)
- integrity rules (anti-cheating, AI disclosure)

## 3) Assessment types (standard set)
- **Formative checks:** low-stakes, frequent
- **Summative tasks:** unit/course proof
- **Portfolio artifacts:** selected best evidence
- **Benchmarking tests:** only when appropriate and documented

## 4) Outcomes (what we measure)
Minimum outcomes categories:
- literacy (reading/writing/speaking)
- math mastery
- science reasoning
- historical understanding
- formation/service (measured with clear rubric)
- Hebrew proficiency (where applicable)

## 5) Reporting rules
- Reports must include:
  - what was measured
  - what was found
  - what changed (if gaps exist)
- Do not hide gaps; log corrective actions.

## 6) Evidence this chapter drives (folders/files)
- `04-assessment-outcomes/assessment-plan/*` (later)
- `04-assessment-outcomes/rubrics/*` (later)
- `04-assessment-outcomes/reports/*` (later)

## 7) Implementation checklist (Day 0–Day 45)
- [ ] Publish core rubric set (writing, math, formation)
- [ ] Publish assessment calendar template
- [ ] Publish monthly report template
- [ ] Publish AI integrity disclosure line template (later policies pack)

---

## Revision History
- v0.1 — Chapter scaffold created