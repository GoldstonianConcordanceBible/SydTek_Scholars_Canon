# CH-17 — Technology, Privacy, and AI Integrity
**Status:** Draft (v0.1)  
**Purpose:** Define acceptable technology use, privacy posture, records handling rules, and AI integrity expectations.

---

## 1) Purpose
Technology must:
- support learning
- protect privacy
- preserve academic integrity
- remain auditable and governable

## 2) Scope
Applies to:
- student/parent/staff acceptable use
- platform/tool approval
- data classification and retention
- AI use in learning and grading
- incident response for data events

## 3) Privacy principles (public-safe)
1. Collect only what is needed.
2. Restrict access by role.
3. Log access for sensitive records.
4. Avoid publishing personal data.
5. Respond quickly to incidents.

## 4) Tooling posture
- Maintain an approved tools list.
- Vet tools for privacy, security, and age-appropriateness.
- Require vendor review for tools that handle student data.

## 5) AI integrity (audit-friendly)
- AI may be used as a learning aid where allowed.
- Students must disclose AI assistance when required.
- Teachers must not outsource grading in a way that breaks integrity or privacy.
- No AI tool may be used with private student info unless approved and governed.

## 6) Evidence this chapter drives (folders/files)
- `01-policies-pack/privacy-records/*` (later)
- `01-policies-pack/tech-acceptable-use/*` (later)
- `01-policies-pack/academics-integrity/*` (later)
- `01-policies-pack/tools/*` (later)

## 7) Implementation checklist (Day 0–Day 45)
- [ ] Publish data classification standard
- [ ] Publish staff/parent/student AUPs
- [ ] Publish AI integrity policy + disclosure line template
- [ ] Publish data incident response SOP

---

## Revision History
- v0.1 — Chapter scaffold created